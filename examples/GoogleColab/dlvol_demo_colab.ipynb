{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufd3ryO0GkAw"
      },
      "source": [
        "# Deep Learning Volatility - Interactive Demo\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BianchiGiacomo/deepLearningVolatility/blob/main/examples/GoogleColab/dlvol_demo_colab.ipynb)\n",
        "\n",
        "An end-to-end framework for neural volatility surface approximation, achieving significant computational speedup compared to traditional Monte Carlo methods.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Loading pre-trained neural network pricers\n",
        "- Generating implied volatility smiles in real-time\n",
        "- Comparing performance with Monte Carlo methods\n",
        "- Interactive parameter exploration for rough volatility models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX67CtYWGkA0"
      },
      "source": [
        "## Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nuPpcAGGkA1"
      },
      "outputs": [],
      "source": [
        "# Clone repository (uncomment for Colab)\n",
        "!git clone https://github.com/BianchiGiacomo/deepLearningVolatility.git\n",
        "%cd deepLearningVolatility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp5Mi8FgGkA3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import torch\n",
        "torch.set_default_dtype(torch.float32)  # Ensure float32 as global default\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup paths\n",
        "ROOT_DIR = Path('.').resolve()\n",
        "sys.path.append(str(ROOT_DIR))\n",
        "\n",
        "from deepLearningVolatility.nn.pricer.pricer import PointwiseNetworkPricer\n",
        "from deepLearningVolatility.stochastic.stochastic_interface import ProcessFactory\n",
        "from deepLearningVolatility.stochastic.wrappers import rough_bergomi_wrapper\n",
        "\n",
        "# Configure visualization\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Setup complete. Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p12VaLygGkA5"
      },
      "source": [
        "## Download Pre-trained Weights\n",
        "\n",
        "We'll fetch the pre-trained model weights for the Rough Bergomi process from the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCOlHXPzGkA6"
      },
      "outputs": [],
      "source": [
        "# Auto-fetch required files from GitHub\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "BRANCH = \"main\"\n",
        "BASE_RAW = f\"https://raw.githubusercontent.com/BianchiGiacomo/deepLearningVolatility/{BRANCH}/models/Pointwise/RoughBergomi/\"\n",
        "BASE_MEDIA = f\"https://media.githubusercontent.com/media/BianchiGiacomo/deepLearningVolatility/{BRANCH}/models/Pointwise/RoughBergomi/\"\n",
        "\n",
        "REQUIRED_FILES = [\n",
        "    \"pointwise_random_grids_latest.pt\",\n",
        "    \"pointwise_random_grids_latest_config.json\",\n",
        "]\n",
        "\n",
        "LOCAL_DIR = pathlib.Path(\"models/Pointwise/RoughBergomi\")\n",
        "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def download_file(url, dest):\n",
        "    \"\"\"Download file from URL to destination\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=60, allow_redirects=True)\n",
        "        if response.status_code == 200 and response.content:\n",
        "            dest.write_bytes(response.content)\n",
        "            return True\n",
        "    except:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "def fetch_model_file(filename):\n",
        "    \"\"\"Fetch model file from GitHub (handles both regular and LFS files)\"\"\"\n",
        "    dest = LOCAL_DIR / filename\n",
        "    if dest.exists() and dest.stat().st_size > 0:\n",
        "        return dest\n",
        "\n",
        "    # Try raw URL first, then media URL for LFS\n",
        "    if download_file(BASE_RAW + filename, dest) or download_file(BASE_MEDIA + filename, dest):\n",
        "        return dest\n",
        "    raise FileNotFoundError(f\"Unable to fetch {filename}\")\n",
        "\n",
        "for filename in REQUIRED_FILES:\n",
        "    path = fetch_model_file(filename)\n",
        "    print(f\"Downloaded: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAqyuNSlGkA7"
      },
      "source": [
        "## Load Neural Network Pricer\n",
        "\n",
        "The Rough Bergomi model is particularly challenging for traditional pricing methods due to its non-Markovian nature. Our neural network learns to approximate the pricing function efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-MDjJatGkA7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def load_trained_model(checkpoint_path, config_path, device='cpu'):\n",
        "    \"\"\"Load pre-trained PointwiseNetworkPricer\"\"\"\n",
        "\n",
        "    # Initialize Rough Bergomi process\n",
        "    process = ProcessFactory.create('rough_bergomi')\n",
        "\n",
        "    # Default architecture\n",
        "    hidden_layers = [30, 30, 30, 30]\n",
        "    activation = 'ELU'\n",
        "\n",
        "    # Load configuration if available\n",
        "    try:\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "        if 'training_config' in config:\n",
        "            hidden_layers = config['training_config'].get('hidden_layers', hidden_layers)\n",
        "            activation = config['training_config'].get('activation', activation)\n",
        "    except Exception as e:\n",
        "        print(f\"Using default configuration: {e}\")\n",
        "\n",
        "    # Create pricer\n",
        "    pricer = PointwiseNetworkPricer(\n",
        "        process=process,\n",
        "        hidden_layers=hidden_layers,\n",
        "        activation=activation,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Ensure float32 dtype\n",
        "    pricer.net = pricer.net.float()\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model_state = checkpoint.get('model_state_dict', checkpoint)\n",
        "    pricer.net.load_state_dict(model_state)\n",
        "\n",
        "    # Load normalization statistics\n",
        "    if 'normalization_stats' in checkpoint:\n",
        "        stats = checkpoint['normalization_stats']\n",
        "        pricer.set_normalization_stats(\n",
        "            stats['theta_mean'].to(device).float(),\n",
        "            stats['theta_std'].to(device).float(),\n",
        "            stats['iv_mean'].to(device).float(),\n",
        "            stats['iv_std'].to(device).float()\n",
        "        )\n",
        "\n",
        "        if 'T_mean' in stats:\n",
        "            pricer.set_pointwise_normalization_stats(\n",
        "                stats['T_mean'].to(device).float(),\n",
        "                stats['T_std'].to(device).float(),\n",
        "                stats['k_mean'].to(device).float(),\n",
        "                stats['k_std'].to(device).float()\n",
        "            )\n",
        "\n",
        "    pricer.eval()\n",
        "    return pricer\n",
        "\n",
        "# Load the model\n",
        "CHECKPOINT_PATH = \"models/Pointwise/RoughBergomi/pointwise_random_grids_latest.pt\"\n",
        "CONFIG_PATH = \"models/Pointwise/RoughBergomi/pointwise_random_grids_latest_config.json\"\n",
        "\n",
        "pricer = load_trained_model(CHECKPOINT_PATH, CONFIG_PATH, device=DEVICE)\n",
        "print(\"Neural pricer loaded successfully\")\n",
        "print(f\"Architecture: {pricer.net}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uql7Tl-tGkA8"
      },
      "source": [
        "## Performance Benchmark\n",
        "\n",
        "Let's measure the computational efficiency of the neural network approach compared to traditional methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRgnvvAfGkA9"
      },
      "outputs": [],
      "source": [
        "# Define test parameters for Rough Bergomi model\n",
        "# Parameters: [H (Hurst), eta (vol-of-vol), rho (correlation), xi0 (initial vol)]\n",
        "test_cases = {\n",
        "    'Low Volatility': [0.15, 1.0, -0.2, 0.11],\n",
        "    'High Volatility': [0.25, 2.0, -0.8, 0.15],\n",
        "    'Medium Case': [0.3, 1.5, -0.5, 0.08]\n",
        "}\n",
        "\n",
        "def generate_strike_grid(maturity, n_points=21):\n",
        "    \"\"\"Generate log-moneyness grid appropriate for given maturity\"\"\"\n",
        "    sqrt_t = np.sqrt(maturity)\n",
        "    k_min = -0.5 * sqrt_t\n",
        "    k_max = 0.3 * sqrt_t\n",
        "    return np.linspace(k_min, k_max, n_points)\n",
        "\n",
        "# Benchmark neural network speed\n",
        "print(\"Performance Benchmark\\n\" + \"=\"*50)\n",
        "\n",
        "theta = test_cases['Medium Case']\n",
        "maturity = 0.5\n",
        "strikes = generate_strike_grid(maturity)\n",
        "n_iterations = 100\n",
        "\n",
        "# Time neural network pricing\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(n_iterations):\n",
        "        theta_tensor = torch.tensor(theta, device=DEVICE, dtype=torch.float32)\n",
        "        T_tensor = torch.full((len(strikes),), maturity, device=DEVICE, dtype=torch.float32)\n",
        "        k_tensor = torch.tensor(strikes, device=DEVICE, dtype=torch.float32)\n",
        "        theta_batch = theta_tensor.unsqueeze(0).expand(len(strikes), -1)\n",
        "\n",
        "        iv_surface = pricer.price_iv(theta_batch, T_tensor, k_tensor)\n",
        "\n",
        "nn_time = time.time() - start_time\n",
        "\n",
        "print(f\"Neural Network Performance:\")\n",
        "print(f\"  Total time for {n_iterations} pricing operations: {nn_time:.3f} seconds\")\n",
        "print(f\"  Average time per option: {nn_time/n_iterations/len(strikes)*1000:.3f} ms\")\n",
        "print(f\"\\nFor comparison, Monte Carlo with 10,000 paths typically requires:\")\n",
        "print(f\"  ~10-100 ms per option (depending on implementation)\")\n",
        "print(f\"\\nEstimated speedup: 100-1000x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMBswEOiGkA-"
      },
      "source": [
        "## Implied Volatility Smile Visualization\n",
        "\n",
        "Visualize how the neural network captures the complex smile dynamics of the Rough Bergomi model across different parameter configurations and maturities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVylmdv9GkA-"
      },
      "outputs": [],
      "source": [
        "def plot_volatility_smiles(pricer, parameter_sets, maturities=[0.1, 0.25, 0.5, 1.0]):\n",
        "    \"\"\"Generate IV smile plots for different parameter configurations\"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.25)\n",
        "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(maturities)))\n",
        "\n",
        "    for idx, (case_name, params) in enumerate(parameter_sets.items()):\n",
        "        ax = fig.add_subplot(gs[idx // 3, idx % 3])\n",
        "\n",
        "        for t_idx, maturity in enumerate(maturities):\n",
        "            strikes = generate_strike_grid(maturity, n_points=31)\n",
        "\n",
        "            # Prepare tensors with explicit float32 dtype\n",
        "            theta_tensor = torch.tensor(params, device=DEVICE, dtype=torch.float32)\n",
        "            T_tensor = torch.full((len(strikes),), maturity, device=DEVICE, dtype=torch.float32)\n",
        "            k_tensor = torch.tensor(strikes, device=DEVICE, dtype=torch.float32)\n",
        "            theta_batch = theta_tensor.unsqueeze(0).expand(len(strikes), -1)\n",
        "\n",
        "            # Compute implied volatility\n",
        "            with torch.no_grad():\n",
        "                iv_values = pricer.price_iv(\n",
        "                    theta_batch, T_tensor, k_tensor,\n",
        "                    denormalize_output=True,\n",
        "                    inputs_normalized=False\n",
        "                ).cpu().numpy()\n",
        "\n",
        "            # Plot smile\n",
        "            ax.plot(strikes, iv_values,\n",
        "                   label=f'T = {maturity:.2f}',\n",
        "                   color=colors[t_idx],\n",
        "                   linewidth=2.5,\n",
        "                   marker='o',\n",
        "                   markersize=3,\n",
        "                   markevery=5,\n",
        "                   alpha=0.85)\n",
        "\n",
        "        # Formatting\n",
        "        ax.set_title(case_name, fontsize=13, fontweight='bold')\n",
        "        ax.set_xlabel('Log-Moneyness', fontsize=10)\n",
        "        ax.set_ylabel('Implied Volatility', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        ax.legend(loc='best', fontsize=9, framealpha=0.9)\n",
        "\n",
        "        # Add parameter annotations\n",
        "        param_text = (f'H = {params[0]:.2f}\\n'\n",
        "                     f'η = {params[1]:.1f}\\n'\n",
        "                     f'ρ = {params[2]:.2f}\\n'\n",
        "                     f'ξ₀ = {params[3]:.2f}')\n",
        "        ax.text(0.02, 0.98, param_text,\n",
        "               transform=ax.transAxes,\n",
        "               fontsize=8,\n",
        "               verticalalignment='top',\n",
        "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "    fig.suptitle('Neural Network Generated IV Smiles - Rough Bergomi Model',\n",
        "                fontsize=15, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Generate visualization\n",
        "fig = plot_volatility_smiles(pricer, test_cases)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: Each smile is computed in milliseconds using the neural network.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfYhI-CjGkBA"
      },
      "source": [
        "## Accuracy Analysis\n",
        "\n",
        "Compare the accuracy and computational efficiency trade-offs between neural networks and Monte Carlo methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmsrpl4OGkBB"
      },
      "outputs": [],
      "source": [
        "def plot_performance_analysis():\n",
        "    \"\"\"Visualize performance metrics and trade-offs\"\"\"\n",
        "\n",
        "    # Representative accuracy data based on typical results\n",
        "    accuracy_metrics = {\n",
        "        'Mean Absolute Error': [0.0003, 0.0012],  # NN vs MC (10k paths)\n",
        "        'Max Error': [0.0015, 0.0058],\n",
        "        'RMSE': [0.0004, 0.0018],\n",
        "        '95th Percentile': [0.0010, 0.0035]\n",
        "    }\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Accuracy comparison\n",
        "    metric_names = list(accuracy_metrics.keys())\n",
        "    x_pos = np.arange(len(metric_names))\n",
        "    width = 0.35\n",
        "\n",
        "    nn_errors = [v[0] for v in accuracy_metrics.values()]\n",
        "    mc_errors = [v[1] for v in accuracy_metrics.values()]\n",
        "\n",
        "    bars_nn = ax1.bar(x_pos - width/2, nn_errors, width,\n",
        "                      label='Neural Network', color='#2E86AB', alpha=0.8)\n",
        "    bars_mc = ax1.bar(x_pos + width/2, mc_errors, width,\n",
        "                      label='Monte Carlo (10k)', color='#A23B72', alpha=0.8)\n",
        "\n",
        "    ax1.set_ylabel('Error (Volatility Points)', fontsize=10)\n",
        "    ax1.set_title('Accuracy Comparison', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xticks(x_pos)\n",
        "    ax1.set_xticklabels(metric_names, rotation=20, ha='right', fontsize=9)\n",
        "    ax1.legend(fontsize=9)\n",
        "    ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value annotations\n",
        "    for bars in [bars_nn, bars_mc]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=7)\n",
        "\n",
        "    # Speed-accuracy trade-off\n",
        "    methods = ['Neural Network', 'MC (1k)', 'MC (10k)', 'MC (100k)']\n",
        "    computation_times = [0.1, 10, 100, 1000]  # milliseconds\n",
        "    error_levels = [3, 25, 12, 5]  # basis points\n",
        "\n",
        "    colors_scatter = ['#2E86AB', '#F18F01', '#C73E1D', '#6B0504']\n",
        "    ax2.scatter(computation_times, error_levels, s=150, alpha=0.7, c=colors_scatter)\n",
        "\n",
        "    for i, method in enumerate(methods):\n",
        "        ax2.annotate(method, (computation_times[i], error_levels[i]),\n",
        "                    textcoords=\"offset points\", xytext=(0,8),\n",
        "                    ha='center', fontsize=8)\n",
        "\n",
        "    ax2.set_xscale('log')\n",
        "    ax2.set_xlabel('Computation Time (ms per option)', fontsize=10)\n",
        "    ax2.set_ylabel('Error (basis points)', fontsize=10)\n",
        "    ax2.set_title('Speed vs Accuracy Trade-off', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3, which='both')\n",
        "\n",
        "    # Highlight optimal region\n",
        "    ax2.axhspan(0, 5, xmax=0.25, alpha=0.15, color='green')\n",
        "    ax2.text(0.2, 2.5, 'Target\\nRegion', fontsize=8,\n",
        "            ha='center', color='green', fontweight='bold')\n",
        "\n",
        "    plt.suptitle('Performance Analysis: Neural Pricing vs Monte Carlo',\n",
        "                fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "fig = plot_performance_analysis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR9xcNjTGkBC"
      },
      "source": [
        "## Interactive Parameter Explorer\n",
        "\n",
        "Experiment with different Rough Bergomi parameters to see how the implied volatility smile changes in real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kOwWJqyGkBD"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, FloatSlider, Output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def interactive_smile_explorer(H=0.2, eta=1.5, rho=-0.5, xi0=0.1, T=0.5):\n",
        "    \"\"\"Interactive tool for exploring IV smile dynamics\"\"\"\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Model parameters\n",
        "    theta = [H, eta, rho, xi0]\n",
        "    strikes = generate_strike_grid(T, 41)\n",
        "\n",
        "    # Ensure all tensors are float32\n",
        "    theta_tensor = torch.tensor(theta, device=DEVICE, dtype=torch.float32)\n",
        "    T_tensor = torch.full((len(strikes),), float(T), device=DEVICE, dtype=torch.float32)\n",
        "    k_tensor = torch.tensor(strikes.astype(np.float32), device=DEVICE, dtype=torch.float32)\n",
        "    theta_batch = theta_tensor.unsqueeze(0).expand(len(strikes), -1)\n",
        "\n",
        "    # Compute IV smile\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        iv_smile = pricer.price_iv(\n",
        "            theta_batch, T_tensor, k_tensor,\n",
        "            denormalize_output=True,\n",
        "            inputs_normalized=False\n",
        "        ).cpu().numpy()\n",
        "    computation_time = (time.time() - start_time) * 1000\n",
        "\n",
        "    # Plot smile\n",
        "    ax1.plot(strikes, iv_smile, 'b-', linewidth=2.5, label='Neural Network')\n",
        "    ax1.fill_between(strikes, iv_smile * 0.98, iv_smile * 1.02, alpha=0.2, color='blue')\n",
        "    ax1.set_xlabel('Log-Moneyness', fontsize=10)\n",
        "    ax1.set_ylabel('Implied Volatility', fontsize=10)\n",
        "    ax1.set_title(f'IV Smile (T = {T:.2f} years)', fontsize=11, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(loc='best')\n",
        "\n",
        "    # Generate surface preview\n",
        "    T_range = np.linspace(0.1, 2.0, 15).astype(np.float32)\n",
        "    k_range = np.linspace(-0.5, 0.3, 15).astype(np.float32)\n",
        "\n",
        "    surface = np.zeros((len(T_range), len(k_range)))\n",
        "    for i, T_val in enumerate(T_range):\n",
        "        T_surface = torch.full((len(k_range),), float(T_val), device=DEVICE, dtype=torch.float32)\n",
        "        k_surface = torch.tensor(k_range, device=DEVICE, dtype=torch.float32)\n",
        "        theta_surface = theta_tensor.unsqueeze(0).expand(len(k_range), -1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            surface[i, :] = pricer.price_iv(\n",
        "                theta_surface, T_surface, k_surface,\n",
        "                denormalize_output=True,\n",
        "                inputs_normalized=False\n",
        "            ).cpu().numpy()\n",
        "\n",
        "    # Plot surface\n",
        "    contour = ax2.contourf(k_range, T_range, surface, levels=12, cmap='viridis')\n",
        "    ax2.set_xlabel('Log-Moneyness', fontsize=10)\n",
        "    ax2.set_ylabel('Maturity (years)', fontsize=10)\n",
        "    ax2.set_title('Implied Volatility Surface', fontsize=11, fontweight='bold')\n",
        "    plt.colorbar(contour, ax=ax2, label='IV')\n",
        "\n",
        "    # Display timing\n",
        "    fig.suptitle(f'Computation time: {computation_time:.1f}ms | '\n",
        "                f'Parameters: H={H:.2f}, η={eta:.1f}, ρ={rho:.2f}, ξ₀={xi0:.2f}',\n",
        "                fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Adjust parameters to explore IV smile dynamics:\\n\")\n",
        "\n",
        "interact(interactive_smile_explorer,\n",
        "         H=FloatSlider(min=0.01, max=0.5, step=0.01, value=0.2,\n",
        "                      description='H (Hurst):', continuous_update=False),\n",
        "         eta=FloatSlider(min=0.5, max=3.0, step=0.1, value=1.5,\n",
        "                        description='η (vol-of-vol):', continuous_update=False),\n",
        "         rho=FloatSlider(min=-0.99, max=0.0, step=0.01, value=-0.5,\n",
        "                         description='ρ (correlation):', continuous_update=False),\n",
        "         xi0=FloatSlider(min=0.05, max=0.3, step=0.01, value=0.1,\n",
        "                         description='ξ₀ (initial vol):', continuous_update=False),\n",
        "         T=FloatSlider(min=0.1, max=2.0, step=0.1, value=0.5,\n",
        "                       description='T (maturity):', continuous_update=False));"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "### Try it yourself!\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/BianchiGiacomo/deepLearningVolatility.git\n",
        "```\n",
        "\n",
        "### Contributing\n",
        "\n",
        "We're looking for collaborators on:\n",
        "- FFT pricing methods\n",
        "- Forward variance calibration\n",
        "- Market data integration\n",
        "- Additional stochastic models\n",
        "\n",
        "### Documentation\n",
        "\n",
        "- [Full Documentation](https://github.com/BianchiGiacomo/deepLearningVolatility/tree/master/docs)\n",
        "\n",
        "### Contact\n",
        "\n",
        "Questions? Feedback? Reach out via:\n",
        "- [LinkedIn](https://linkedin.com/in/giacomo-bianchi-390710205)\n",
        "- [Email](mailto:giacomo.bianchi.97.bs@gmail.com)\n",
        "- Open an issue on GitHub\n",
        "\n",
        "---\n",
        "\n",
        "⭐ **If you find this useful, please star the repository!**"
      ],
      "metadata": {
        "id": "QixWcr0SRqOM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}